{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip_new\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Owlv2ForObjectDetection, Owlv2Processor\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset_name = 'cifar10'\n",
    "zeroshot_dataset_name = 'cifar10'\n",
    "prompt_type = 'deep'\n",
    "clip_model = 'ViT-L/14' # [ViT-B/32, ViT-L/14]\n",
    "prompt_len = 3\n",
    "batch_size = 32\n",
    "epochs_num = 20\n",
    "learning_rate = 0.004\n",
    "\n",
    "root = # '/path/to/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECORDataset(Dataset):\n",
    "    def __init__(self, preprocess, json_path, cat2id, rat2id, max_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.preprocess = preprocess\n",
    "        self.datas = pd.read_json(json_path)    \n",
    "        self.cat2id = cat2id\n",
    "        self.rat2id = rat2id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.preprocess(Image.open(self.datas.iloc[index]['image']))\n",
    "        category = self.cat2id[self.datas.iloc[index]['category']]\n",
    "\n",
    "        rationales = torch.tensor(pd.Series(self.datas.iloc[index]['unqiue_rationales']).apply(lambda rat: self.rat2id[rat]).values)    \n",
    "        rationales = torch.cat([rationales, -torch.ones(self.max_length-len(rationales))]).to(int)\n",
    "        return image, category, rationales\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLR:\n",
    "    def __init__(self, optimizer, base_lr, warmup_steps, total_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.base_lr = base_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        self._counter = 0\n",
    "        self.step()\n",
    "\n",
    "    def step(self):\n",
    "        if self._counter < self.warmup_steps:\n",
    "            lr = self.base_lr * (self._counter+1)/self.warmup_steps\n",
    "        \n",
    "        else:\n",
    "            e = self._counter - self.warmup_steps\n",
    "            es = self.total_steps - self.warmup_steps\n",
    "            lr = 0.5 * (1 + np.cos(np.pi * e / es)) * self.base_lr\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        self._counter += 1\n",
    "        \n",
    "\n",
    "class VisionPromptTuning(nn.Module):\n",
    "    def __init__(self, prompt_type, prompt_len, width, layers):\n",
    "        super().__init__()\n",
    "        assert prompt_type in {'shallow', 'deep'}\n",
    "        self.prompt_type = prompt_type\n",
    "        self.prompt_len = prompt_len\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "\n",
    "        scale = width ** (-0.5)\n",
    "        if prompt_type == 'shallow':\n",
    "            self.weights = nn.Parameter(scale * torch.randn(prompt_len, width))\n",
    "        else:\n",
    "            self.weights = nn.Parameter(scale * torch.randn(layers,prompt_len, width))\n",
    "        \n",
    "        self.pos_embeddings = nn.Parameter(scale * torch.randn(prompt_len, width))\n",
    "\n",
    "    def forward(self):\n",
    "        return self.weights, self.pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nowl_processor = Owlv2Processor.from_pretrained(\"google/owlv2-base-patch16-ensemble\")\\nowl_model = Owlv2ForObjectDetection.from_pretrained(\"google/owlv2-base-patch16-ensemble\").to(device)\\n\\nfor param in model.parameters():\\n    param.requires_grad = False\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load models\n",
    "model, preprocess = clip_new.load(clip_model, device)\n",
    "model = model.to(torch.float32)\n",
    "model = model.eval()\n",
    "\n",
    "tokenPrompts = VisionPromptTuning(prompt_type, prompt_len, model.vision_width, model.vision_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 :  Loss:  5.398271606863961\n"
     ]
    }
   ],
   "source": [
    "# load the learnt prompt if neccesacry\n",
    "tokenPrompts = VisionPromptTuning(prompt_type, prompt_len, model.vision_width, model.vision_layers).to(device)\n",
    "save_file = torch.load(f'{root}/ECOR_new/DROR_checkpoints/{dataset_name}.pth.tar')\n",
    "tokenPrompts.load_state_dict(save_file['tokenPrompts'])\n",
    "print(\"Epoch \", save_file['epoch'], \": \", \"Loss: \", save_file['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncat_names = np.array(list(cat2id.keys()))\\nrat_names = np.array(list(rat2id.keys()))\\n\\ncat_names_zeroshot = np.array(list(cat2id.keys()))\\nrat_names_zeroshot = np.array(list(rat2id.keys()))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_cat_rat(json_path):\n",
    "        \n",
    "        datas = pd.read_json(json_path)\n",
    "        rationales = []\n",
    "\n",
    "        for _, data in datas.iterrows():\n",
    "            rationales.extend(data['unqiue_rationales'])\n",
    "        \n",
    "        unique_rats = pd.Series(rationales).apply(lambda rat: rat.lower().strip()).unique()\n",
    "        rat2id = dict(zip(unique_rats, range(len(unique_rats))))\n",
    "        \n",
    "        unique_cats = datas['category'].apply(lambda cat: cat.lower().strip()).unique()\n",
    "        cat2id = dict(zip(unique_cats, range(len(unique_cats))))\n",
    "        \n",
    "        maxLength = datas['unqiue_rationales'].apply(lambda rats: len(rats)).max()        \n",
    "        \n",
    "        return cat2id, rat2id, maxLength\n",
    "\n",
    "train_cat2id, train_rat2id, train_maxLength = preprocess_cat_rat(f'{root}/Datasets/{dataset_name}_dr/stats_train.json')\n",
    "test_cat2id, test_rat2id, test_maxLength = preprocess_cat_rat(f'{root}/Datasets/{dataset_name}_dr/stats_test.json')\n",
    "zeroshot_cat2id, zeroshot_rat2id, zeroshot_maxLength = preprocess_cat_rat(f'{root}/Datasets/{zeroshot_dataset_name}_dr/stats_test.json')\n",
    "\n",
    "\"\"\"\n",
    "cat_names = np.array(list(cat2id.keys()))\n",
    "rat_names = np.array(list(rat2id.keys()))\n",
    "\n",
    "cat_names_zeroshot = np.array(list(cat2id.keys()))\n",
    "rat_names_zeroshot = np.array(list(rat2id.keys()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset = ECORDataset(preprocess, f'{root}/Datasets/{dataset_name}_dr/stats_train.json', train_cat2id, train_rat2id, train_maxLength)\n",
    "trainLoader = DataLoader(trainset, batch_size, shuffle=True)\n",
    "\n",
    "testset = ECORDataset(preprocess, f'{root}/Datasets/{dataset_name}_dr/stats_test.json', test_cat2id, test_rat2id, test_maxLength)\n",
    "testLoader = DataLoader(testset, batch_size)\n",
    "\n",
    "\n",
    "zeroshot_set = ECORDataset(preprocess, f'{root}/Datasets/{zeroshot_dataset_name}_dr/stats_test.json', zeroshot_cat2id, zeroshot_rat2id, zeroshot_maxLength)\n",
    "zeroshot_loader = DataLoader(zeroshot_set, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cat_rat_embeddings(model, cat2id, rat2id):\n",
    "    cats_embed = []\n",
    "    rats_embed = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(cat2id)/block_size).astype(int)\n",
    "        \n",
    "        for i in range(block_num):\n",
    "            if i != (block_num-1):\n",
    "                cats_tokens_temp = clip_new.tokenize(pd.Series(list(cat2id.keys())[i*block_size:(i+1)*block_size]).apply(lambda cat: 'A photo of a ' + cat)).to(device)\n",
    "            else:\n",
    "                cats_tokens_temp = clip_new.tokenize(pd.Series(list(cat2id.keys())[i*block_size:]).apply(lambda cat: 'A photo of a ' + cat)).to(device)\n",
    "\n",
    "            cats_embeds_temp = model.encode_text(cats_tokens_temp)\n",
    "            cats_embeds_temp /= cats_embeds_temp.norm(dim=1, keepdim=True)\n",
    "\n",
    "            cats_embed.append(cats_embeds_temp)\n",
    "        \n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(rat2id)/block_size).astype(int)\n",
    "\n",
    "        for i in range(block_num):\n",
    "            if i != (block_num-1):\n",
    "                rats_tokens_pos_temp = clip_new.tokenize(pd.Series(list(rat2id.keys())[i*block_size:(i+1)*block_size]).apply(lambda rat: 'There is ' + rat)).to(device)\n",
    "            else:\n",
    "                rats_tokens_pos_temp = clip_new.tokenize(pd.Series(list(rat2id.keys())[i*block_size:]).apply(lambda rat: 'There is ' + rat)).to(device)\n",
    "\n",
    "            rats_embeds_pos_temp = model.encode_text(rats_tokens_pos_temp)\n",
    "            rats_embeds_pos_temp /= rats_embeds_pos_temp.norm(dim=1, keepdim=True)\n",
    "\n",
    "            rats_embed.append(rats_embeds_pos_temp)\n",
    "\n",
    "        cats_embed = torch.cat(cats_embed, dim=0)\n",
    "        rats_embed = torch.cat(rats_embed, dim=0)\n",
    "    \n",
    "    return cats_embed, rats_embed\n",
    "\n",
    "\n",
    "\n",
    "train_cats_embed, train_rats_embed = compute_cat_rat_embeddings(model, train_cat2id, train_rat2id)\n",
    "test_cats_embed, test_rats_embed = compute_cat_rat_embeddings(model, test_cat2id, test_rat2id)\n",
    "cats_embed_zeroshot, rats_embed_zeroshot = compute_cat_rat_embeddings(model, zeroshot_cat2id, zeroshot_rat2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionality Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cat_rat_embeddings_DROR(model, cat2id, rat2id):\n",
    "    with torch.no_grad():\n",
    "        cats_rats_embed = []\n",
    "        cats_rats_prompts = []\n",
    "        rats_cats_prompts = []\n",
    "        rats_cats_embed = []\n",
    "\n",
    "        for rat in cat2id.keys():\n",
    "            for cat in rat2id.keys():  \n",
    "                cats_rats_prompt_temp = f\"This is a photo of a {cat} because there is {rat}\"\n",
    "                cats_rats_prompts.append(cats_rats_prompt_temp)\n",
    "\n",
    "        for cat in rat2id.keys():\n",
    "            for rat in cat2id.keys():  \n",
    "                rats_cats_prompt_temp = f\"This is a photo of a {rat} because there is {cat}\"\n",
    "                rats_cats_prompts.append(rats_cats_prompt_temp)\n",
    "        \n",
    "\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(cats_rats_prompts)/block_size).astype(int)\n",
    "        for i in range(block_num):\n",
    "            if i != (block_num-1):\n",
    "                cats_rats_tokens_temp = clip.tokenize(cats_rats_prompts[i*block_size:(i+1)*block_size]).to(device)\n",
    "            else:\n",
    "                cats_rats_tokens_temp = clip.tokenize(cats_rats_prompts[i*block_size:]).to(device)\n",
    "            \n",
    "            cats_rats_embed_temp = model.encode_text(cats_rats_tokens_temp)\n",
    "            cats_rats_embed_temp /= cats_rats_embed_temp.norm(dim=1, keepdim=True)\n",
    "            cats_rats_embed.append(cats_rats_embed_temp)\n",
    "        \n",
    "\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(rats_cats_prompts)/block_size).astype(int)\n",
    "        for i in range(block_num):\n",
    "            if i != (block_num-1):\n",
    "                rats_cats_tokens_temp = clip.tokenize(rats_cats_prompts[i*block_size:(i+1)*block_size]).to(device)\n",
    "            else:\n",
    "                rats_cats_tokens_temp = clip.tokenize(rats_cats_prompts[i*block_size:]).to(device)\n",
    "            \n",
    "            rats_cats_embed_temp = model.encode_text(rats_cats_tokens_temp)\n",
    "            rats_cats_embed_temp /= rats_cats_embed_temp.norm(dim=1, keepdim=True)\n",
    "            rats_cats_embed.append(rats_cats_embed_temp)\n",
    "\n",
    "\n",
    "        cats_rats_embed = torch.cat(cats_rats_embed, dim=0)\n",
    "        rats_cats_embed = torch.cat(rats_cats_embed, dim=0)\n",
    "    \n",
    "        return cats_rats_embed, rats_cats_embed\n",
    "\n",
    "\n",
    "train_cats_rats_embed, train_rats_cats_embed = compute_cat_rat_embeddings_DROR(model, train_cat2id, train_rat2id)\n",
    "test_cats_rats_embed, test_rats_cats_embed = compute_cat_rat_embeddings_DROR(model, test_cat2id, test_rat2id)\n",
    "zeroshot_cats_rats_embed, zeroshot_cats_rats_prompts = compute_cat_rat_embeddings_DROR(model, zeroshot_cat2id, zeroshot_rat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0021806955337524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ratios = []\n",
    "    for (imgs, cats, rats) in tqdm(trainLoader):\n",
    "        images = imgs.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        images_embed = model.encode_image(images)\n",
    "        images_embed /= images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        cat_projections = []\n",
    "        rat_projections = []\n",
    "        for img_embed, cat, rat in zip(images_embed, cats, rats):\n",
    "            re = train_rats_embed[rat[0]][None, :] # 1 x d\n",
    "            hyper_plane = torch.cat([re.t(), img_embed[:, None]], dim=1) # d x 2\n",
    "            res = torch.linalg.lstsq(hyper_plane, train_cats_embed.t())\n",
    "            cat_projection = hyper_plane @ res.solution # d x |C|\n",
    "            groundtruth_dir = hyper_plane.sum(dim=1, keepdim=True)\n",
    "            groundtruth_dir /= groundtruth_dir.norm(dim=0, keepdim=True) # d x 1          \n",
    "            cat_projections.append(torch.squeeze(groundtruth_dir.t() @ cat_projection)) # |C|\n",
    "\n",
    "            ce = train_cats_embed[cat][None, :] # 1 x d\n",
    "            hyper_plane = torch.cat([ce.t(), img_embed[:, None]], dim=1) # d x 2\n",
    "            ces = torch.linalg.lstsq(hyper_plane, train_rats_embed.t())\n",
    "            rat_projection = hyper_plane @ ces.solution\n",
    "            groundtruth_dir = hyper_plane.sum(dim=1, keepdim=True)\n",
    "            groundtruth_dir /= groundtruth_dir.norm(dim=0, keepdim=True) # d x 1          \n",
    "            rat_projections.append(torch.squeeze(groundtruth_dir.t() @ rat_projection)) # |R|\n",
    "\n",
    "        logits_cat = torch.stack(cat_projections, dim=0) # B x |C|\n",
    "        logits_rat = torch.stack(rat_projections, dim=0) # B x |R|\n",
    "        probs_cat_rat = logits_cat.softmax(dim=-1) # B x |C|\n",
    "        probs_rat_cat = logits_rat.softmax(dim=-1) # B x |R|\n",
    "        \n",
    "\n",
    "        logits_cat = images_embed @ train_cats_embed.t() # B x |C|\n",
    "        logits_rat = images_embed @ train_rats_embed.t() # B x |R|\n",
    "        probs_cat = logits_cat.softmax(dim=-1)\n",
    "        probs_rat = logits_rat.softmax(dim=-1)\n",
    "        \n",
    "        idxs = torch.arange(probs_cat.shape[0]).to(device)\n",
    "        ratio = (probs_cat[idxs, cats] * probs_rat_cat[idxs, rats[:,0]]) / (probs_rat[idxs, rats[:, 0]] * probs_cat_rat[idxs, cats])\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    ratios = torch.cat(ratios, dim=0)\n",
    "    print(ratios.mean().item())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.16597747802734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ratios = []\n",
    "    for (imgs, cats, rats) in tqdm(trainLoader):\n",
    "        images = imgs.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        images_embed = model.encode_image(images)\n",
    "        images_embed /= images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        cat_projections = []\n",
    "        rat_projections = []\n",
    "        for img_embed, cat, rat in zip(images_embed, cats, rats):\n",
    "            re = train_rats_embed[rat[0]][None, :] # 1 x d\n",
    "            res = torch.linalg.lstsq(re.t(), train_cats_embed.t())\n",
    "            cat_projection = re.t() @ res.solution # d x |C|\n",
    "            cat_projections.append(cat_projection)\n",
    "\n",
    "            ce = train_cats_embed[cat][None, :] # 1 x d\n",
    "            ces = torch.linalg.lstsq(ce.t(), train_rats_embed.t())\n",
    "            rat_projection = ce.t() @ ces.solution\n",
    "            rat_projections.append(rat_projection)\n",
    "\n",
    "        cat_projections = torch.stack(cat_projections, dim=0) # B x d x |C|\n",
    "        rat_projections = torch.stack(rat_projections, dim=0) # B x d x |R|\n",
    "        logits_cat = model.logit_scale.exp() * torch.squeeze(images_embed[:, None, :] @ cat_projections) # B x |C|\n",
    "        logits_rat = model.logit_scale.exp() * torch.squeeze(images_embed[:, None, :] @ rat_projections) # B x |R|\n",
    "        probs_cat_rat = logits_cat.softmax(dim=-1) # B x |C|\n",
    "        probs_rat_cat = logits_rat.softmax(dim=-1) # B x |R|\n",
    "\n",
    "        logits_cat = model.logit_scale.exp() * images_embed @ train_cats_embed.t() # B x |C|\n",
    "        logits_rat = model.logit_scale.exp() * images_embed @ train_rats_embed.t() # B x |R|\n",
    "        probs_cat = logits_cat.softmax(dim=-1)\n",
    "        probs_rat = logits_rat.softmax(dim=-1)\n",
    "        \n",
    "        idxs = torch.arange(probs_cat.shape[0]).to(device)\n",
    "        ratio = (probs_cat[idxs, cats] * probs_rat_cat[idxs, rats[:,0]]) / (probs_rat[idxs, rats[:, 0]] * probs_cat_rat[idxs, cats])\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    ratios = torch.cat(ratios, dim=0)\n",
    "    print(ratios.mean().item())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/343 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [03:43<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.392852783203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ratios = []\n",
    "    for (imgs, cats, rats) in tqdm(trainLoader):\n",
    "        images = imgs.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        images_embed = model.encode_image(images)\n",
    "        images_embed /= images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        logist_cat_rat = images_embed @ train_cats_rats_embed.t() # B x |C|*|R|\n",
    "        logist_rat_cat = images_embed @ train_rats_cats_embed.t() # B x |R|*|C|\n",
    "        probs_cat_rat = logist_cat_rat.softmax(dim=-1)\n",
    "        probs_rat_cat = logist_rat_cat.softmax(dim=-1)\n",
    "\n",
    "        logits_cat = images_embed @ train_cats_embed.t() # B x |C|\n",
    "        logits_rat = images_embed @ train_rats_embed.t() # B x |R|\n",
    "        probs_cat = logits_cat.softmax(dim=-1)\n",
    "        probs_rat = logits_rat.softmax(dim=-1)\n",
    "        \n",
    "        idxs = torch.arange(probs_cat.shape[0]).to(device)\n",
    "        ratio = (probs_cat[idxs, cats] * probs_rat_cat[idxs, cats*len(train_rat2id)+rats[:,0]]) / (probs_rat[idxs, rats[:, 0]] * probs_cat_rat[idxs, rats[:,0]*len(train_cat2id)+cats])\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    ratios = torch.cat(ratios, dim=0)\n",
    "    print(ratios.mean().item())      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROR Evaluation on Multi-Rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 18.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def DROR_compute_cat_rat_embeddings(model, cat2id, rat2id):\n",
    "    with torch.no_grad():\n",
    "        cats_rats_embed = []\n",
    "        cats_rats_prompts = []\n",
    "\n",
    "        for rat in rat2id.keys():\n",
    "            for cat in cat2id.keys():  \n",
    "                cats_rats_prompt_temp = f\"This is a photo of a {cat} because there is {rat}\"\n",
    "                cats_rats_prompts.append(cats_rats_prompt_temp)\n",
    "\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(cats_rats_prompts)/block_size).astype(int)\n",
    "        for i in tqdm(range(block_num), total=block_num):\n",
    "            if i != (block_num-1):\n",
    "                cats_rats_tokens_temp = clip_new.tokenize(cats_rats_prompts[i*block_size:(i+1)*block_size]).to(device)\n",
    "            else:\n",
    "                cats_rats_tokens_temp = clip_new.tokenize(cats_rats_prompts[i*block_size:]).to(device)\n",
    "            \n",
    "            cats_rats_embed_temp = model.encode_text(cats_rats_tokens_temp)\n",
    "            cats_rats_embed_temp /= cats_rats_embed_temp.norm(dim=1, keepdim=True)\n",
    "            cats_rats_embed.append(cats_rats_embed_temp)\n",
    "        \n",
    "        cats_rats_embed = torch.cat(cats_rats_embed, dim=0)\n",
    "    \n",
    "        return cats_rats_embed\n",
    "\n",
    "\n",
    "DROR_train_cats_rats_embed = DROR_compute_cat_rat_embeddings(model, train_cat2id, train_rat2id)\n",
    "DROR_test_cats_rats_embed = DROR_compute_cat_rat_embeddings(model, test_cat2id, test_rat2id)\n",
    "DROR_zeroshot_cats_rats_embed = DROR_compute_cat_rat_embeddings(model, zeroshot_cat2id, zeroshot_rat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_RR(pred_rats:list, target_rats:list, pred_cats:list, target_cat:int):\n",
    "    # Compute Category Accuracy\n",
    "    acc_cat = 0.\n",
    "    cats_vote = pd.Series(pred_cats).value_counts()\n",
    "    max_vote_num = cats_vote.iloc[0]\n",
    "    j=0\n",
    "    while j<len(cats_vote) and cats_vote.iloc[j] == max_vote_num:\n",
    "        if cats_vote.index[j] == target_cat:\n",
    "            acc_cat = 1.\n",
    "            break\n",
    "        j += 1\n",
    "    \n",
    "    # Compute Rationales Accuracy\n",
    "    acc_rat = len(set(pred_rats) & set(target_rats)) / len(target_rats)\n",
    "\n",
    "    return acc_cat, acc_rat\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluation(model, testLoader, cats_rats_embed, cat2id):\n",
    "    RRs = []\n",
    "    RWs = []\n",
    "    WRs = []\n",
    "    WWs = []\n",
    "\n",
    "    for (images, cats, rats) in tqdm(testLoader, total=len(testLoader)):\n",
    "        images = images.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        prompt, pos_embedding = tokenPrompts()\n",
    "        images_embed = model.encode_image(images, prompt, pos_embedding)\n",
    "        images_embed = images_embed / images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        logits_cats_rats = images_embed @ cats_rats_embed.t() # B x |R||C|\n",
    "        \n",
    "        for (logits_cat_rat, cat, rat) in zip(logits_cats_rats, cats, rats):\n",
    "            target_rat = rat[rat!=-1]\n",
    "            preds_cat_rat = torch.topk(logits_cat_rat, k=len(target_rat), dim=0)[1]\n",
    "            preds_rat = preds_cat_rat // len(cat2id)\n",
    "            preds_cat = preds_cat_rat % len(cat2id)\n",
    "            \n",
    "            acc_cat, acc_rat = compute_RR(preds_rat.cpu().tolist(), target_rat.cpu().tolist(), preds_cat.cpu().tolist(), cat.item())\n",
    "            RRs.append(acc_cat * acc_rat)\n",
    "            RWs.append(acc_cat * (1-acc_rat))\n",
    "            WRs.append((1-acc_cat) * acc_rat)\n",
    "            WWs.append((1-acc_cat) * (1-acc_rat))\n",
    "\n",
    "    RR = np.mean(RRs)\n",
    "    RW = np.mean(RWs)\n",
    "    WR = np.mean(WRs)\n",
    "    WW = np.mean(WWs)\n",
    "    print(f\"RR: {100*RR}, RW: {100*RW}, WR: {100*WR}, WW: {100*WW}\")\n",
    "    return RR, RW, WR, WW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:06<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 28.325324013397406, RW: 66.78170962574632, WR: 1.6972477064220184, WW: 3.1957186544342515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation(model, zeroshot_loader, DROR_zeroshot_cats_rats_embed, zeroshot_cat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [03:05<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 11.957717381824523, RW: 44.13529674690388, WR: 5.178516919588348, WW: 38.72846895168324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation(model, testLoader, DROR_test_cats_rats_embed, test_cat2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECOR Evaluation on Multi-Rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 805/805 [00:42<00:00, 19.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def ECOR_compute_cat_rat_embeddings(model, cat2id, rat2id):\n",
    "    with torch.no_grad():\n",
    "        cats_rats_embed = []\n",
    "        cats_rats_prompts = []\n",
    "        rats_prompts = []\n",
    "        rats_embed = []\n",
    "\n",
    "        for rat in rat2id.keys():\n",
    "            rats_prompt_temp = f\"There is {rat}\"\n",
    "            rats_prompts.append(rats_prompt_temp)\n",
    "        \n",
    "        for rat in rat2id.keys():\n",
    "            for cat in cat2id.keys():  \n",
    "                cats_rats_prompts_temp = f\"This is a photo of a {cat} because there is {rat}\"\n",
    "                cats_rats_prompts.append(cats_rats_prompts_temp)\n",
    "\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(rats_prompts)/block_size).astype(int)\n",
    "        for i in range(block_num):\n",
    "            if i != (block_num-1):\n",
    "                rats_tokens_temp = clip_new.tokenize(rats_prompts[i*block_size:(i+1)*block_size]).to(device)\n",
    "            else:\n",
    "                rats_tokens_temp = clip_new.tokenize(rats_prompts[i*block_size:]).to(device)\n",
    "            \n",
    "            rats_embed_temp = model.encode_text(rats_tokens_temp)\n",
    "            rats_embed_temp /= rats_embed_temp.norm(dim=1, keepdim=True)\n",
    "            rats_embed.append(rats_embed_temp)\n",
    "        \n",
    "        rats_embed = torch.cat(rats_embed, dim=0)\n",
    "\n",
    "        block_size = 50\n",
    "        block_num = np.ceil(len(cats_rats_prompts)/block_size).astype(int)\n",
    "        for i in tqdm(range(block_num), total=block_num):\n",
    "            if i != (block_num-1):\n",
    "                cats_rats_tokens_temp = clip_new.tokenize(cats_rats_prompts[i*block_size:(i+1)*block_size]).to(device)\n",
    "            else:\n",
    "                cats_rats_tokens_temp = clip_new.tokenize(cats_rats_prompts[i*block_size:]).to(device)\n",
    "            \n",
    "            cats_rats_embed_temp = model.encode_text(cats_rats_tokens_temp)\n",
    "            cats_rats_embed_temp /= cats_rats_embed_temp.norm(dim=1, keepdim=True)\n",
    "            cats_rats_embed.append(cats_rats_embed_temp)\n",
    "        \n",
    "        cats_rats_embed = torch.cat(cats_rats_embed, dim=0)\n",
    "    \n",
    "        return rats_embed, cats_rats_embed\n",
    "\n",
    "\n",
    "ECOR_train_rats_embed, ECOR_train_cats_rats_embed = ECOR_compute_cat_rat_embeddings(model, train_cat2id, train_rat2id)\n",
    "ECOR_test_rats_embed, ECOR_test_cats_rats_embed = ECOR_compute_cat_rat_embeddings(model, test_cat2id, test_rat2id)\n",
    "ECOR_zeroshot_rats_embed, ECOR_zeroshot_cats_rats_embed = ECOR_compute_cat_rat_embeddings(model, zeroshot_cat2id, zeroshot_rat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_RR(pred_rats:list, target_rats:list, pred_cats:list, target_cat:int):\n",
    "    # Compute Category Accuracy\n",
    "    acc_cat = 0.\n",
    "    cats_vote = pd.Series(pred_cats).value_counts()\n",
    "    max_vote_num = cats_vote.iloc[0]\n",
    "    j=0\n",
    "    while j<len(cats_vote) and cats_vote.iloc[j] == max_vote_num:\n",
    "        if cats_vote.index[j] == target_cat:\n",
    "            acc_cat = 1.\n",
    "            break\n",
    "        j += 1\n",
    "    \n",
    "    # Compute Rationales Accuracy\n",
    "    acc_rat = len(set(pred_rats) & set(target_rats)) / len(target_rats)\n",
    "\n",
    "    return acc_cat, acc_rat\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluation(model, testLoader, rats_embed, cats_rats_embed, cat2id):\n",
    "    RRs = []\n",
    "    RWs = []\n",
    "    WRs = []\n",
    "    WWs = []\n",
    "\n",
    "    for (images, cats, rats) in tqdm(testLoader, total=len(testLoader)):\n",
    "        images = images.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        prompt, pos_embedding = tokenPrompts()\n",
    "        images_embed = model.encode_image(images, prompt, pos_embedding)\n",
    "        images_embed = images_embed / images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        logits_rats = images_embed @ rats_embed.t() # B x |R|\n",
    "        probs_rats = logits_rats.softmax(dim=-1) # B x |R|\n",
    "        logits_cats_rats = images_embed @ cats_rats_embed.t() # B x |R||C|\n",
    "        probs_cats = logits_cats_rats.softmax(dim=-1) # B x |R||C|\n",
    "        probs_cats_rats = probs_cats * torch.repeat_interleave(probs_rats, len(cat2id), dim=-1) # B x |R||C|\n",
    "\n",
    "        for (probs_cat_rat, cat, rat) in zip(probs_cats_rats, cats, rats):\n",
    "            target_rat = rat[rat!=-1]\n",
    "            preds_cat_rat = torch.topk(probs_cat_rat, k=len(target_rat), dim=0)[1]\n",
    "            preds_rat = preds_cat_rat // len(cat2id)\n",
    "            preds_cat = preds_cat_rat % len(cat2id)\n",
    "            \n",
    "            acc_cat, acc_rat = compute_RR(preds_rat.cpu().tolist(), target_rat.cpu().tolist(), preds_cat.cpu().tolist(), cat.item())\n",
    "            RRs.append(acc_cat * acc_rat)\n",
    "            RWs.append(acc_cat * (1-acc_rat))\n",
    "            WRs.append((1-acc_cat) * acc_rat)\n",
    "            WWs.append((1-acc_cat) * (1-acc_rat))\n",
    "\n",
    "    RR = np.mean(RRs)\n",
    "    RW = np.mean(RWs)\n",
    "    WR = np.mean(WRs)\n",
    "    WW = np.mean(WWs)\n",
    "    print(f\"RR: {100*RR}, RW: {100*RW}, WR: {100*WR}, WW: {100*WW}\")\n",
    "    return RR, RW, WR, WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:50<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 19.28219129822089, RW: 63.619576067171636, WR: 2.9912121034192545, WW: 14.107020531188224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation(model, zeroshot_loader, ECOR_zeroshot_rats_embed, ECOR_zeroshot_cats_rats_embed, zeroshot_cat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [03:26<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 12.77706526749894, RW: 45.00354697739902, WR: 5.415436321048565, WW: 36.80395143405348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation(model, testLoader, ECOR_test_rats_embed, ECOR_test_cats_rats_embed, test_cat2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_RR(pred_rats:list, target_rats:list, pred_cats:list, target_cat:int):\n",
    "    # Compute Category Accuracy\n",
    "    acc_cat = 0.\n",
    "    cats_vote = pd.Series(pred_cats).value_counts()\n",
    "    max_vote_num = cats_vote.iloc[0]\n",
    "    j=0\n",
    "    while j<len(cats_vote) and cats_vote.iloc[j] == max_vote_num:\n",
    "        if cats_vote.index[j] == target_cat:\n",
    "            acc_cat = 1.\n",
    "            break\n",
    "        j += 1\n",
    "    \n",
    "    # Compute Rationales Accuracy\n",
    "    acc_rat = len(set(pred_rats) & set(target_rats)) / len(target_rats)\n",
    "\n",
    "    return acc_cat, acc_rat\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluation(model, testLoader, cats_embed, rats_embed, tokenPrompts=None):\n",
    "    RRs = []\n",
    "    RWs = []\n",
    "    WRs = []\n",
    "    WWs = []\n",
    "\n",
    "    for (images, cats, rats) in tqdm(testLoader, total=len(testLoader)):\n",
    "        images = images.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        prompt, pos_embedding = None, None\n",
    "        if tokenPrompts:\n",
    "            prompt, pos_embedding = tokenPrompts()\n",
    "\n",
    "        images_embed = model.encode_image(images, prompt, pos_embedding)    \n",
    "        images_embed = images_embed / images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        logits_rat = images_embed @ rats_embed.t() # B x |R|\n",
    "        probs_rat = logits_rat.softmax(dim=-1)\n",
    "        \n",
    "        for i, (img_embed, cat, rat) in enumerate(zip(images_embed, cats, rats)):\n",
    "            hyper_planes = torch.stack([rats_embed, img_embed.expand(rats_embed.shape)], dim=-1) # |R| x d x 2\n",
    "            res = torch.linalg.lstsq(hyper_planes, cats_embed.t()[None,:,:])\n",
    "            cat_projection = hyper_planes @ res.solution # |R| x d x |C|\n",
    "            groundtruth_dir = hyper_planes.sum(dim=-1) # |R| x d\n",
    "            groundtruth_dir /= groundtruth_dir.norm(dim=-1, keepdim=True) # |R| x d\n",
    "            \n",
    "            proj_cats_logit = torch.squeeze(groundtruth_dir[:, None, :] @ cat_projection, dim=1) # |R| x |C|\n",
    "            probs_proj_cat = proj_cats_logit.softmax(dim=-1) # |R| x |C|\n",
    "            probs_cat_rat = probs_rat[i,:][:, None] * probs_proj_cat # |R| x |C|\n",
    "        \n",
    "            target_rat = rat[rat!=-1]\n",
    "            preds_cat_rat = torch.topk(probs_cat_rat.reshape((-1,)), k=len(target_rat), dim=0)[1]\n",
    "            preds_rat = preds_cat_rat // probs_cat_rat.shape[1]\n",
    "            preds_cat = preds_cat_rat % probs_cat_rat.shape[1]\n",
    "            \n",
    "            acc_cat, acc_rat = compute_RR(preds_rat.cpu().tolist(), target_rat.cpu().tolist(), preds_cat.cpu().tolist(), cat.item())\n",
    "            RRs.append(acc_cat * acc_rat)\n",
    "            RWs.append(acc_cat * (1-acc_rat))\n",
    "            WRs.append((1-acc_cat) * acc_rat)\n",
    "            WWs.append((1-acc_cat) * (1-acc_rat))\n",
    "\n",
    "    RR = np.mean(RRs)\n",
    "    RW = np.mean(RWs)\n",
    "    WR = np.mean(WRs)\n",
    "    WW = np.mean(WWs)\n",
    "    print(f\"RR: {RR}, RW: {RW}, WR: {WR}, WW: {WW}\")\n",
    "    return RR, RW, WR, WW\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluation_MR(model, testLoader, cats_embed, rats_embed, tokenPrompts=None, k_beam=5):\n",
    "    RRs = []\n",
    "    RWs = []\n",
    "    WRs = []\n",
    "    WWs = []\n",
    "    rat_idxs = torch.arange(rats_embed.shape[0]).to(device)\n",
    "\n",
    "    for (images, cats, rats) in tqdm(testLoader, total=len(testLoader)):\n",
    "        print(\"yes..............\")\n",
    "        images = images.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "\n",
    "        prompt, pos_embedding = None, None\n",
    "        if tokenPrompts:\n",
    "            prompt, pos_embedding = tokenPrompts()\n",
    "\n",
    "        images_embed = model.encode_image(images, prompt, pos_embedding)    \n",
    "        images_embed = images_embed / images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        logits_rat = images_embed @ rats_embed.t() # B x |R|\n",
    "        probs_rat = logits_rat.softmax(dim=-1) # B x |R|\n",
    "        \n",
    "        for i, (img_embed, cat, rat) in enumerate(zip(images_embed, cats, rats)):\n",
    "            target_rat = rat[rat!=-1]   \n",
    "            choosed_rats_mask = torch.zeros(k_beam, rats_embed.shape[0], dtype=torch.bool).to(device)\n",
    "            for k in range(len(target_rat)):\n",
    "                choosed_rats_embed = rats_embed[None, :, :].expand((k_beam,-1,-1))[choosed_rats_mask].reshape((k_beam, k, rats_embed.shape[-1])) # k_beam x k x d\n",
    "                remained_rats_embed = rats_embed[None, :, :].expand((k_beam,-1,-1))[~choosed_rats_mask].reshape((k_beam, rats_embed.shape[0]-k, -1)) # k_beam x (|R|-k) x d\n",
    "                hyper_planes = torch.stack([remained_rats_embed, img_embed[None, None, :].expand(remained_rats_embed.shape)], dim=-1) # k_beam x (|R|-k) x d x 2\n",
    "                hyper_planes = torch.cat([hyper_planes, choosed_rats_embed.permute(0,2,1)[:, None, :, :].expand((-1, hyper_planes.shape[1], -1, -1))], dim=-1) # k_beam x |R|-k x d x (k+2)\n",
    "                res = torch.linalg.lstsq(hyper_planes, cats_embed.t()[None, None,:,:])\n",
    "                cat_projection = hyper_planes @ res.solution # k_beam x (|R|-k) x d x |C|\n",
    "                groundtruth_dir = hyper_planes.sum(dim=-1) # k_beam x (|R|-k) x d\n",
    "                groundtruth_dir /= groundtruth_dir.norm(dim=-1, keepdim=True) # k_beam x (|R|-k) x d\n",
    "                \n",
    "                proj_cats_logit = torch.squeeze(groundtruth_dir[:, :, None, :] @ cat_projection, dim=-2) # k_beam x (|R|-k) x |C|\n",
    "                probs_proj_cat = proj_cats_logit.softmax(dim=-1) # k_beam x (|R|-k) x |C|\n",
    "                probs_cat_rat = probs_rat[i][None, :].expand((k_beam, -1))[~choosed_rats_mask].reshape((k_beam, -1, 1)) * probs_proj_cat # k_beam x (|R|-k) x |C|\n",
    "                preds_cat_rat = torch.topk(probs_cat_rat.reshape((-1,),), k=k_beam, dim=0)[1]              \n",
    "                pred_rat = rat_idxs[None, :].expand((k_beam, -1))[~choosed_rats_mask][preds_cat_rat // probs_cat_rat.shape[-1]]\n",
    "                choosed_rats_mask = choosed_rats_mask[(preds_cat_rat // probs_cat_rat.shape[-1])//probs_cat_rat.shape[1]]\n",
    "                choosed_rats_mask[torch.arange(k_beam), pred_rat] = True\n",
    "           \n",
    "           \n",
    "            choosed_rats_embed = rats_embed[None, :, :].expand((k_beam, -1, -1))[choosed_rats_mask].reshape((k_beam, len(target_rat), -1)) # k-Beam x m x d\n",
    "            hyper_plane = torch.cat([choosed_rats_embed.permute(0,2,1), img_embed[None, :, None].expand(k_beam, -1, -1)], dim=-1) # k_beam x d x (m+1)\n",
    "            res = torch.linalg.lstsq(hyper_plane, cats_embed.t()[None, :, :])\n",
    "            cat_projection = hyper_plane @ res.solution # k_beam x d x |C|\n",
    "            groundtruth_dir = hyper_plane.sum(dim=-1) # k_beam x d\n",
    "            groundtruth_dir /= groundtruth_dir.norm(dim=-1, keepdim=True) # k_beam x d\n",
    "            \n",
    "            proj_cats_logit = torch.squeeze(groundtruth_dir[:, None, :] @ cat_projection, dim=-2) # k_beam x |C|\n",
    "            probs_proj_cat = proj_cats_logit.softmax(dim=-1) # k_beam x |C|\n",
    "            preds_cat = torch.topk(probs_proj_cat.reshape(-1), k=len(target_rat), dim=0)[1]\n",
    "            preds_rat = rat_idxs[choosed_rats_mask[(preds_cat//probs_proj_cat.shape[-1])[0]]]\n",
    "            preds_cat = preds_cat % probs_proj_cat.shape[-1]\n",
    "            \n",
    "            acc_cat, acc_rat = compute_RR(preds_rat.cpu().tolist(), target_rat.cpu().tolist(), preds_cat.cpu().tolist(), cat.item())\n",
    "            RRs.append(acc_cat * acc_rat)\n",
    "            RWs.append(acc_cat * (1-acc_rat))\n",
    "            WRs.append((1-acc_cat) * acc_rat)\n",
    "            WWs.append((1-acc_cat) * (1-acc_rat))\n",
    "            \n",
    "\n",
    "    RR = np.mean(RRs)\n",
    "    RW = np.mean(RWs)\n",
    "    WR = np.mean(WRs)\n",
    "    WW = np.mean(WWs)\n",
    "    print(f\"RR: {RR}, RW: {RW}, WR: {WR}, WW: {WW}\")\n",
    "    return RR, RW, WR, WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/589 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/589 [01:21<13:21:13, 81.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/589 [02:22<11:17:53, 69.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/589 [03:12<9:49:58, 60.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/589 [04:19<10:16:13, 63.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/589 [05:11<9:35:14, 59.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/589 [05:57<8:51:25, 54.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/589 [06:51<8:48:40, 54.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 8/589 [07:35<8:15:50, 51.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/589 [08:18<7:50:26, 48.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/589 [09:11<8:02:04, 49.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/589 [10:21<8:59:10, 55.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/589 [11:15<8:52:32, 55.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/589 [12:14<9:03:31, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/589 [12:58<8:26:02, 52.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/589 [13:48<8:17:08, 51.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/589 [14:47<8:33:59, 53.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/589 [16:11<10:00:41, 63.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/589 [16:21<9:10:20, 57.73s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m RR, RW, WR, WW \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_MR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cats_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rats_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_beam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/DROR/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 226\u001b[0m, in \u001b[0;36mevaluation_MR\u001b[0;34m(model, testLoader, cats_embed, rats_embed, tokenPrompts, k_beam)\u001b[0m\n\u001b[1;32m    224\u001b[0m hyper_planes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([remained_rats_embed, img_embed[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mexpand(remained_rats_embed\u001b[38;5;241m.\u001b[39mshape)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# k_beam x (|R|-k) x d x 2\u001b[39;00m\n\u001b[1;32m    225\u001b[0m hyper_planes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([hyper_planes, choosed_rats_embed\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mexpand((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, hyper_planes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# k_beam x |R|-k x d x (k+2)\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyper_planes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcats_embed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m cat_projection \u001b[38;5;241m=\u001b[39m hyper_planes \u001b[38;5;241m@\u001b[39m res\u001b[38;5;241m.\u001b[39msolution \u001b[38;5;66;03m# k_beam x (|R|-k) x d x |C|\u001b[39;00m\n\u001b[1;32m    228\u001b[0m groundtruth_dir \u001b[38;5;241m=\u001b[39m hyper_planes\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# k_beam x (|R|-k) x d\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation_MR(model, testLoader, test_cats_embed, test_rats_embed, k_beam=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: total loss = 3.9587723180847463, cat loss= 0.17338008843207756, rat loss = 3.7853922296526687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: total loss = 3.3979001796674266, cat loss= 0.21006648302243128, rat loss = 3.1878336966449954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: total loss = 3.1523674646724804, cat loss= 0.2204651695110656, rat loss = 2.931902295161415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: total loss = 3.022326851513541, cat loss= 0.2036431256789884, rat loss = 2.8186837258345525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: total loss = 2.9372972411980767, cat loss= 0.18820132972623632, rat loss = 2.7490959114718403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: total loss = 2.858408327316183, cat loss= 0.17891029127323446, rat loss = 2.6794980360429483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: total loss = 2.7967814322081836, cat loss= 0.16828056634049526, rat loss = 2.6285008658676885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: total loss = 2.753096593201243, cat loss= 0.1617149345442797, rat loss = 2.5913816586569633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: total loss = 2.7255153322739223, cat loss= 0.15603383907721086, rat loss = 2.5694814931967116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: total loss = 2.7010565672590197, cat loss= 0.1559157376055236, rat loss = 2.545140829653496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: total loss = 2.6789399683269393, cat loss= 0.152598964001463, rat loss = 2.5263410043254764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: total loss = 2.6536190257939722, cat loss= 0.1500606792843688, rat loss = 2.5035583465096036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: total loss = 2.6462323541339505, cat loss= 0.14767584804430048, rat loss = 2.49855650608965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: total loss = 2.6239817103842484, cat loss= 0.1487511885384636, rat loss = 2.4752305218457846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: total loss = 2.599507568123265, cat loss= 0.14520309525406708, rat loss = 2.4543044728691976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: total loss = 2.58743215656297, cat loss= 0.1459647879767055, rat loss = 2.4414673685862645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: total loss = 2.5788938277201368, cat loss= 0.14456028498472184, rat loss = 2.434333542735415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: total loss = 2.5658058038710476, cat loss= 0.14513832703232765, rat loss = 2.42066747683872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: total loss = 2.5591547728244364, cat loss= 0.14441786020128558, rat loss = 2.414736912623151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: total loss = 2.5560864763718256, cat loss= 0.1441927102509046, rat loss = 2.411893766120921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_steps = epochs_num * len(trainLoader)\n",
    "warmup_steps = 0.2 * total_steps\n",
    "optimizer = torch.optim.AdamW(tokenPrompts.parameters(), learning_rate)\n",
    "scheduler = CosineLR(optimizer, learning_rate, warmup_steps, total_steps)\n",
    "\n",
    "criterion_cat = torch.nn.CrossEntropyLoss()\n",
    "criterion_rat = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "prev_RR_zeroshot = 0.\n",
    "\n",
    "for epoch in range(epochs_num):\n",
    "    \n",
    "    cumLoss_cat= 0.0\n",
    "    cumLoss_rat= 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.eval()\n",
    "    tokenPrompts.train()\n",
    "\n",
    "    for (images, cats, rats) in tqdm(trainLoader, total=len(trainLoader)):\n",
    "        images = images.to(device)\n",
    "        cats = cats.to(device)\n",
    "        rats = rats.to(device)\n",
    "        \n",
    "        prompt, pos_embedding = tokenPrompts()\n",
    "        images_embed = model.encode_image(images, prompt, pos_embedding)\n",
    "        images_embed = images_embed / images_embed.norm(dim=1, keepdim=True) # B x d\n",
    "        \n",
    "        # Compute Loss rat\n",
    "        logits_rat =  model.logit_scale.exp() * torch.squeeze(images_embed @ train_rats_embed.t()) # B x |R|\n",
    "        probs_rat = logits_rat.softmax(dim=-1) # B x |R|\n",
    "\n",
    "        logits_cat = []\n",
    "        target_rats = torch.zeros_like(logits_rat).to(device)\n",
    "\n",
    "        for i, (img_embed, cat, rat) in enumerate(zip(images_embed, cats, rats)):\n",
    "            target_rat = rat[rat!=-1]\n",
    "            target_rat_embed = train_rats_embed[target_rat] # m x d\n",
    "            hyper_plane = torch.cat([target_rat_embed, img_embed[None, :]], dim=0) # (m+1) x d\n",
    "            res = torch.linalg.lstsq(hyper_plane.t(), train_cats_embed.t())\n",
    "            cat_projection = hyper_plane.t() @ res.solution # d x |C|\n",
    "            groundtruth_dir = hyper_plane.sum(dim=0) # d\n",
    "            groundtruth_dir = groundtruth_dir / groundtruth_dir.norm(dim=-1, keepdim=True) # d\n",
    "            \n",
    "            logits_cat.append(model.logit_scale.exp() * groundtruth_dir[None, :] @ cat_projection) # 1 x |C|\n",
    "            target_rats[i, target_rat] = 1./len(target_rat)\n",
    "\n",
    "        logits_cat = torch.cat(logits_cat, dim=0) # B x |C|\n",
    "\n",
    "        loss_rat = torch.sum(-target_rats * torch.log(probs_rat+1e-12), dim=-1).mean()\n",
    "        #loss_rat = criterion_rat(logits_rat, target_rats)\n",
    "        loss_cat = criterion_cat(logits_cat, cats)\n",
    "        loss_total = loss_rat + loss_cat\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        cumLoss_cat += loss_cat.item() * len(cats)\n",
    "        cumLoss_rat += loss_rat.item() * len(cats)\n",
    "        count += len(cats)\n",
    "        \n",
    "    \n",
    "    cumLoss_cat /= count\n",
    "    cumLoss_rat /= count\n",
    "    print(f'Epoch {epoch+1}: total loss = {cumLoss_cat + cumLoss_rat}, cat loss= {cumLoss_cat}, rat loss = {cumLoss_rat}')\n",
    "\n",
    "    save_file = {'epoch': epoch+1,\n",
    "                 'loss': cumLoss_cat+cumLoss_rat,\n",
    "                 'tokenPrompts': tokenPrompts.state_dict()}\n",
    "\n",
    "    \n",
    "    torch.save(save_file, f'{root}/ECOR_new/ECOR_new_checkpoints/{dataset_name}.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 0.5891655744866754, RW: 0.3955439056356488, WR: 0.0006116207951070337, WW: 0.014678899082568806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation_MR(model, testLoader, test_cats_embed, test_rats_embed, tokenPrompts, k_beam=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 0.5481869812145042, RW: 0.4212319790301442, WR: 0.005657492354740061, WW: 0.02492354740061162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RR, RW, WR, WW = evaluation(model, testLoader, test_cats_embed, test_rats_embed, tokenPrompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DROR)",
   "language": "python",
   "name": "dror"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
